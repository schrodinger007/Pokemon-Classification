import numpy as np
import os 
from pathlib import Path
from keras.preprocessing import image
import matplotlib.pyplot as plt
import pandas as pd
import cv2
labels  =pd.read_csv(r"C:\Users\91914\Downloads\Train (5)\train.csv").values
imageId = labels[:,0]
labels = labels[:,1]
testData = pd.read_csv(r"C:\Users\91914\Downloads\Test (9)\test.csv").values
testId = testData[:,0]
print(type(labels))

labels[labels=="Pikachu"] = 0
labels[labels=="Charmander"] = 2
labels[labels=="Bulbasaur"] = 1
images_data = []
for img in imageId:
    #print(img)
    image = cv2.imread(r'C:\\Users\\91914\\Downloads\\\Train (5)\\Images\\'+img)
    #print(image)
    #CV_Assert(ssize.area() > 0 )
    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
    image  = cv2.resize(image,(32,32))
    images_data.append(image)
# Convert this into numpy array
image_data = np.array(images_data,dtype='float32')/255.0
labels = np.array(labels)

print(image_data.shape,labels.shape)
import random

combined = list(zip(image_data,labels))
random.shuffle(combined)

#Unzip
image_data[:],labels[:] = zip(*combined)
from matplotlib import pyplot as plt

def drawImg(img):
    plt.imshow(img)
    plt.axis("off")
    plt.show()    
    return 

for i in range(10):
    drawImg(image_data[i])
class SVM:
    """SVM Class, Author : Prateek Narang"""
    def __init__(self,C=1.0):
        self.C = C
        self.W = 0
        self.b = 0
        
    def hingeLoss(self,W,b,X,Y):
        loss  = 0.0
        
        loss += .5*np.dot(W,W.T)
        
        m = X.shape[0]
        
        for i in range(m):
            ti = Y[i]*(np.dot(W,X[i].T)+b)
            loss += self.C *max(0,(1-ti))
            
        return loss[0][0]
    
    def fit(self,X,Y,batch_size=50,learning_rate=0.001,maxItr=500):
        
        no_of_features = X.shape[1]
        no_of_samples = X.shape[0]
        
        n = learning_rate
        c = self.C
        
        #Init the model parameters
        W = np.zeros((1,no_of_features))
        bias = 0
        
        #Initial Loss
        
        #Training from here...
        # Weight and Bias update rule that we discussed!
        losses = []
        
        for i in range(maxItr):
            #Training Loop
            
            l = self.hingeLoss(W,bias,X,Y)
            losses.append(l)
            ids = np.arange(no_of_samples)
            np.random.shuffle(ids)
            
            #Batch Gradient Descent(Paper) with random shuffling
            for batch_start in range(0,no_of_samples,batch_size):
                #Assume 0 gradient for the batch
                gradw = 0
                gradb = 0
                
                #Iterate over all examples in the mini batch
                for j in range(batch_start,batch_start+batch_size):
                    if j<no_of_samples:
                        i = ids[j]
                        ti =  Y[i]*(np.dot(W,X[i].T)+bias)
                        
                        if ti>1:
                            gradw += 0
                            gradb += 0
                        else:
                            gradw += c*Y[i]*X[i]
                            gradb += c*Y[i]
                            
                #Gradient for the batch is ready! Update W,B
                W = W - n*W + n*gradw
                bias = bias + n*gradb
                
        
        self.W = W
        self.b = bias
        return W,bias,losses
M = image_data.shape[0] 
image_data = image_data.reshape(M,-1)
print(image_data.shape)
print(labels.shape)

CLASSES = len(np.unique(labels))
print(CLASSES)
def classWiseData(x,y):
    data = {}
    
    for i in range(CLASSES):
        data[i] = []
        
    for i in range(x.shape[0]):
        data[y[i]].append(x[i])
    
    for k in data.keys():
        data[k] = np.array(data[k])
        
    return data
data = classWiseData(image_data,labels)
def getDataPairForSVM(d1,d2):
    """Combines Data of two classes into a signle matrix"""
    
    l1,l2 = d1.shape[0],d2.shape[0]
    
    samples = l1+l2
    features = d1.shape[1]
    
    data_pair = np.zeros((samples,features))
    data_labels = np.zeros((samples,))
    
    data_pair[:l1,:] = d1
    data_pair[l1:,:] = d2
    
    data_labels[:l1] = -1
    data_labels[l1:] = +1
    
    return data_pair,data_labels
mySVM  = SVM()
xp, yp  = getDataPairForSVM(data[0],data[1])
w,b,loss  = mySVM.fit(xp,yp,learning_rate=0.00001,maxItr=1000)
#print(loss)
plt.plot(loss)
def trainSVMs(x,y):
    
    svm_classifiers = {}
    for i in range(CLASSES):
        svm_classifiers[i] = {}
        for j in range(i+1,CLASSES):
            xpair,ypair = getDataPairForSVM(data[i],data[j])
            wts,b,loss = mySVM.fit(xpair,ypair,learning_rate=0.00001,maxItr=1000)
            svm_classifiers[i][j] = (wts,b)
            
            plt.plot(loss)
            plt.show()
            
    
    return svm_classifiers
svm_classifiers = trainSVMs(image_data,labels)
def binaryPredict(x,w,b):
    z  = np.dot(x,w.T) + b
    if z>=0:
        return 1
    else:
        return -1
def predict(x):
    
    count = np.zeros((CLASSES,))
    
    for i in range(CLASSES):
        for j in range(i+1,CLASSES):
            w,b = svm_classifiers[i][j]
            #Take a majority prediction 
            z = binaryPredict(x,w,b)
            
            if(z==1):
                count[j] += 1
            else:
                count[i] += 1
    
    final_prediction = np.argmax(count)
    #print(count)
    return final_prediction

print(predict(image_data[0]))
print(labels[0])
def accuracy(x,y):
    
    count = 0
    for i in range(x.shape[0]):
        prediction = predict(x[i])
        if(prediction==y[i]):
            count += 1
            
    return count/x.shape[0]
accuracy(image_data,labels)
#Test data
testimages_data = []
for img in testId:
    #print(img)
    imagetest = cv2.imread(r'C:\\Users\\91914\\Downloads\\Test (9)\\Images\\'+img)
    #print(image)
    #CV_Assert(ssize.area() > 0 )
    imagetest = cv2.cvtColor(imagetest,cv2.COLOR_BGR2RGB)
    imagetest  = cv2.resize(imagetest,(32,32))
    testimages_data.append(imagetest)

# Convert this into numpy array
testimage_data = np.array(testimages_data,dtype='float32')/255.0


print(testimage_data.shape)

import random

combined = list(testimage_data)
random.shuffle(combined)

from matplotlib import pyplot as plt

def drawImg(img):
    plt.imshow(img)
    plt.axis("off")
    plt.show()    
    return 

for i in range(10):
    drawImg(testimage_data[i])
M1= testimage_data.shape[0] 
testimage_data = testimage_data.reshape(M1,-1)
print(testimage_data.shape)
#print(predict(testimage_data[0]))
pred=[]
labels_dict = {0:"Pikachu",1:"Bulbasaur",2:"Charmander"}
for x in range(testimage_data.shape[0]):
    op = predict(testimage_data[x])
    pred.append(labels_dict[op])
print(pred)
index=[]
testData = pd.read_csv(r"C:\Users\91914\Downloads\Test (9)\test.csv").values
testId = testData[:,0]
#print(testId)
#testId.reshape((1, -1))
for i in (testId):
    #print(i)
    index.append(i)
#print(index)
    
#print(type(index))

df = pd.DataFrame({"ImageId":index, "NameofPokemon":pred})
df.to_csv("pokemonsubmit.csv", index=False)